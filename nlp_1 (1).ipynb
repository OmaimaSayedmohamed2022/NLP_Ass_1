{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkEHGgxMCBC4",
        "outputId": "0292ed13-4206-4079-9988-2fed8399ef8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessed_text: wikipedia wikipedia free encyclopedia english articl  1 967 deutsch artikel articl italiano voci  portugu artigo search wikipedia afrikaan polski asturianu catal cymraeg dansk deutsch eesti  english esperanto euskara galego hrvatski bahasa indonesia italiano ladin latina lietuvi magyar  bahasa melayu bahaso minangkabau nederland norsk norsk nynorsk zbekcha portugu simpl english sinugboanong binisaya srpski srpskohrvatski suomi svenska vi winaray  search read wikipedia languag articl polski deutsch english italiano  nederland portugu sinugboanong binisaya svenska vi winaray  articl afrikaan asturianu catal cymraeg dansk eesti  esperanto euskara galego hrvatski bahasa indonesia ladin latina lietuvi magyar bahasa melayu bahaso minangkabau zbekcha simpl english srpski srpskohrvatski suomi articl bahsa alemannisch bahasa hulontalo basa bali bahasa banjar basa banyumasan bikol central boarisch bosanski brezhoneg bizaad emigli fiji hindi frysk gaeilg g idhlig hausa hornjoserbsc ido igbo ilokano interlingua interlingu jawa kotava kreyl ayisyen l tzebuergesch limburg lombard malagasi  napulitano nordfriisk occitan  plattdtsch runa simi scot chishona shqip sicilianu basa sunda kiswahili tagalog chitumbuka basa ugi volapk walon zazaki isizulu articl dzhudezmo arpitan atikamekw aymar bislama chavacano de zamboanga chichewa corsu vahcuengh dagaar dagbanli deitsch dolnoserbski fulfuld furlan gaelg gagauz gungb  hawai ikinyarwanda kapampangan kasz bsczi kernewek kongo konknni kriyl gwiyannen latgau li niha lingua franca nova livvinkarjala lojban luganda malti twi na vosa nedersaksisch nouormand normaund novial afaan oromoo pangcah papiamentu patoi picard qaraqalpaqsha ripoarisch rumantsch  sakizaya gagana sardu seediq seeltersk sesotho sa leboa setswana soomaaliga sranantongo taqbaylit tayal tetun tok pisin faka tonga vro wolof isixhosa zeuw reo tahiti articl bamanankan batak toba chamoru farefar ghanaian pidgin inuktitut kalaallisut mfants norfuk pitkern pinayuanan  romani ikirundi sesotho siswati xitsonga tyap wayuunaiki languag wikipedia host wikimedia foundat organ also host rang project support work donat download wikipedia android io save favorit articl read offlin sync read list across devic custom read experi offici wikipedia app googl play store appl app store common freeli usabl photo wikivoyag free travel guid wiktionari free dictionari wikibook free textbook wikinew free news sourc wikidata free knowledg base wikivers free cours materi wikiquot free quot compendium mediawiki free open wiki applic wikisourc free librari wikispeci free speci directori wikifunct free function librari commun coordin document page avail creativ common licens term use privaci polici\n",
            "Unique words: {'gungb', 'polski', 'limburg', 'wikifunct', 'bosanski', 'normaund', 'chavacano', 'farefar', 'wikivers', 'sardu', 'afrikaan', 'runa', 'read', 'picard', 'arpitan', 'textbook', 'faka', 'isizulu', '967', 'ido', 'melayu', 'chichewa', 'gagana', 'taqbaylit', 'freeli', 'foundat', 'save', 'simi', 'zeuw', 'kreyl', 'seediq', 'vro', 'pisin', 'kalaallisut', 'mfants', 'bamanankan', 'hrvatski', 'devic', 'wikivoyag', 'nynorsk', 'papiamentu', 'bahasa', 'kongo', 'base', 'isixhosa', 'latina', 'sa', 'xitsonga', '1', 'novial', 'italiano', 'compendium', 'basa', 'leboa', 'usabl', 'atikamekw', 'setswana', 'wikidata', 'wiki', 'sinugboanong', 'travel', 'tok', 'igbo', 'dagbanli', 'cymraeg', 'sunda', 'project', 'romani', 'wikimedia', 'wikibook', 'bahaso', 'lombard', 'ghanaian', 'norsk', 'wikinew', 'tayal', 'zbekcha', 'mediawiki', 'tahiti', 'chamoru', 'kiswahili', 'suomi', 'walon', 'tyap', 'host', 'patoi', 'corsu', 'central', 'sicilianu', 'boarisch', 'na', 'privaci', 'konknni', 'free', 'avail', 'donat', 'custom', 'use', 'svenska', 'sourc', 'luganda', 'voci', 'sync', 'tzebuergesch', 'appl', 'articl', 'eesti', 'frysk', 'interlingu', 'kriyl', 'ikirundi', 'offlin', 'list', 'dictionari', 'directori', 'licens', 'srpskohrvatski', 'soomaaliga', 'sakizaya', 'binisaya', 'io', 'search', 'idhlig', 'hulontalo', 'shqip', 'experi', 'hornjoserbsc', 'languag', 'tetun', 'srpski', 'kapampangan', 'volapk', 'kotava', 'emigli', 'interlingua', 'cours', 'nouormand', 'sesotho', 'bahsa', 'gaelg', 'page', 'simpl', 'speci', 'vi', 'inuktitut', 'euskara', 'galego', 'plattdtsch', 'g', 'pinayuanan', 'hindi', 'latgau', 'dagaar', 'ladin', 'wayuunaiki', 'wikipedia', 'guid', 'batak', 'deitsch', 'tonga', 'ilokano', 'bali', 'bislama', 'lingua', 'pidgin', 'fulfuld', 'dolnoserbski', 'brezhoneg', 'siswati', 'chishona', 'banjar', 'bikol', 'kasz', 'toba', 'chitumbuka', 'open', 'librari', 'nederland', 'zamboanga', 'aymar', 'esperanto', 'norfuk', 'zazaki', 'afaan', 'napulitano', 'nordfriisk', 'dzhudezmo', 'applic', 'wikispeci', 'function', 'furlan', 'niha', 'tagalog', 'nedersaksisch', 'qaraqalpaqsha', 'organ', 'googl', 'across', 'wiktionari', 'knowledg', 'favorit', 'also', 'creativ', 'portugu', 'asturianu', 'vahcuengh', 'gwiyannen', 'wikiquot', 'artikel', 'kernewek', 'occitan', 'winaray', 'oromoo', 'pitkern', 'materi', 'commun', 'play', 'sranantongo', 'encyclopedia', 'ayisyen', 'twi', 'l', 'minangkabau', 'hausa', 'gaeilg', 'quot', 'common', 'ugi', 'ripoarisch', 'ikinyarwanda', 'bsczi', 'download', 'coordin', 'news', 'lietuvi', 'document', 'magyar', 'alemannisch', 'rang', 'deutsch', 'english', 'gagauz', 'li', 'pangcah', 'support', 'artigo', 'dansk', 'bizaad', 'offici', 'vosa', 'term', 'fiji', 'photo', 'indonesia', 'seeltersk', 'livvinkarjala', 'wolof', 'jawa', 'malti', 'wikisourc', 'lojban', 'banyumasan', 'hawai', 'android', 'polici', 'franca', 'nova', 'catal', 'de', 'app', 'reo', 'store', 'work', 'malagasi', 'scot', 'rumantsch'}\n",
            "words less than 3 ['1', 'vi', 'vi', 'g', 'l', 'de', 'li', 'na', 'sa', 'io']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import requests\n",
        "\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "def extract_text_from_html(html_content):\n",
        "    try:\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "        text = soup.get_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred while extracting text:\", str(e))\n",
        "        return None\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Clean HTML tags\n",
        "    cleaned_text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "    # Normalize text (convert to lowercase)\n",
        "    normalized_text = cleaned_text.lower()\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(normalized_text)\n",
        "\n",
        "    # Remove punctuation and non-alphanumeric characters\n",
        "    tokens = [re.sub(r'[^a-zA-Z0-9]', '', token) for token in tokens if token.isalnum()]\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
        "\n",
        "    # Convert tokens back to text\n",
        "    preprocessed_text = ' '.join(stemmed_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "def get_unique_words(preprocessed_text):\n",
        "    words = preprocessed_text.split()\n",
        "    unique_words = set(words)\n",
        "    return unique_words\n",
        "\n",
        "def get_words_less_than3(preprocessed_text):\n",
        "    words = preprocessed_text.split()\n",
        "    words_less_than_3 = [word for word in words if len(word) < 3]\n",
        "    return words_less_than_3\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "url = \"https://www.wikipedia.org/\"\n",
        "html_content = requests.get(url).text\n",
        "text_content = extract_text_from_html(html_content)\n",
        "if text_content:\n",
        "    preprocessed_text = preprocess_text(text_content)\n",
        "\n",
        "    print(\"preprocessed_text:\", preprocessed_text)\n",
        "    unique_words = get_unique_words(preprocessed_text)\n",
        "    print(\"Unique words:\", unique_words)\n",
        "\n",
        "    print(\"words less than 3\",get_words_less_than3(preprocessed_text))\n",
        "\n",
        "else:\n",
        "    print(\"Failed to extract text from\", url)\n"
      ]
    }
  ]
}